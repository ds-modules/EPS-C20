{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-image: url(\"../share/Aerial_view_LLNL.jpg\") ; padding: 0px ; background-size: cover ; border-radius: 15px ; height: 250px; background-position: 0% 80%'>\n",
    "    <div style=\"float: center ; margin: 50px ; padding: 20px ; background: rgba(255 , 255 , 255 , 0.8) ; width: 50% ; height: 150px\">\n",
    "        <div style=\"position: relative ; top: 50% ; transform: translatey(-50%)\">\n",
    "            <div style=\"font-size: xx-large ; font-weight: 900 ; color: rgba(0 , 0 , 0 , 0.9) ; line-height: 100%\">Notebook 2:</div>\n",
    "            <div style=\"font-size: x-large ; padding-top: 20px ; color: rgba(0 , 0 , 0 , 0.7)\">Visualizing Earthquake Magnitudes: <br><br> Amplitude and Distance</div>\n",
    "            <div style=\"font-size: large ; padding-top: 20px ; color: rgba(0 , 0 , 0 , 0.7)\">2014 South Napa Earthquake.</div>\n",
    "            <div style=\"font-size: medium ; padding-top: 20px ; color: rgba(0 , 0 , 0 , 0.7)\">Estimated Time: 30 minutes.</div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to help you explore seismic data resulting from an earthquake.       \n",
    "Primarily to visualise the idea of amplitude and distance to help make seismic magnitudes more intuitive.       \n",
    "In the current example we will explore the 2014 South Napa earthquake. Though, you are welcome to play and explore others.\n",
    "\n",
    "Topics Covered:\n",
    "- Obtaining Data through ObsPy\n",
    "- Plotting Earthquake data with Matplotlib\n",
    "- Querying Event Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Earthquake Magnitudes Demo\n",
    "\n",
    "Now that you have learned some Python basics, you can use your skills to analyze some data. \n",
    "\n",
    "This notebook will provide some exercises using [Obspy](https://github.com/obspy/obspy/wiki), a Python library used to visualize and analyze seimsographic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cells below, we import the required tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --no-cache-dir obspy==1.0.3\n",
    "!pip install matplotlib==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These import a few functions and set the figure size and plot styles for our visualizations\n",
    "# plots inline\n",
    "# can describe these more\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = 16, 10\n",
    "import obspy\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.clients.fdsn.mass_downloader import CircularDomain, \\\n",
    "    Restrictions, MassDownloader\n",
    "from eps_tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Data\n",
    "\n",
    "The first step is to find the event. Below, we import the Obspy Client which lets us query for earthquake events. Then we get the UTC date and time for the 2014 South Napa earthquake happened (August 24th, 2014). We are getting the events with at least a magnitude of 6.0. After, we are printing the events in our resulting catalog, with a local projection centered on the San Francisco Bay Area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Earthquake\n",
    "Here we select and download an earthquake by choosing a data and magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the event \n",
    "client = Client(\"USGS\")\n",
    "t = obspy.UTCDateTime(\"2014-08-24T10:20:44.0\")  # South Napa earthquake\n",
    "cat = client.get_events(starttime=t - 100, endtime=t + 3600,\n",
    "                        minmagnitude=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waveform and Station Data\n",
    "\n",
    "#### Mass Downloader\n",
    "\n",
    "ObsPy has a submodule to help download data, called mass downloader. It attempts to offer an API for how seismologists would like to download data. It works in three steps:\n",
    "\n",
    "1. Define Geographical Domain\n",
    "2. Define Other Restrictions\n",
    "3. Launch Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "\n",
    "##### Part A - Download\n",
    "\n",
    "Use the mass downloader to download data for a small (there are a lot of stations in this region) geographical region (a circular region with a radius of 1 degree is an example), including the station information, with the mass downloader. Download from 2 minutes before the event to 10 minutes after it and download only `BHZ` (Broadband) channels.\n",
    "\n",
    "First we'll import the libraries needed to download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove this \n",
    "import obspy\n",
    "from obspy.clients.fdsn.mass_downloader import CircularDomain, \\\n",
    "    Restrictions, MassDownloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_data is in the eps_tools file\n",
    "\n",
    "download_data(downloaded = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part B - Plot Stations\n",
    "\n",
    "Plot the stations and the event in a single map. \n",
    "The code below reads through the stations file and reads the inventory at each file name. Then the inventory is plotted with a local projection and then a title is added to the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def plot_stations():\n",
    "    for i,filename in enumerate(glob.glob(\"stations/*.xml\")):\n",
    "        if i==0:\n",
    "            inv = obspy.read_inventory(filename)\n",
    "        else:\n",
    "            inv+=obspy.read_inventory(filename)\n",
    "\n",
    "    fig = inv.plot(projection=\"local\", resolution='i',show=False, size=70)\n",
    "    fig = cat.plot(fig=fig,projection=\"local\", resolution='i',show=False, title='Stations Available for South Napa Quake');\n",
    "    plt.show()\n",
    "    \n",
    "plot_stations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part C - Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will filter the data and check that there are no gaps etc.     \n",
    "Don't worry about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eps_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36 Trace(s) in Stream:\n",
       "\n",
       "7D.G01D..BHZ | 2014-08-24T10:20:44.294538Z - 2014-08-24T10:25:32.294538Z | 0.5 Hz, 145 samples\n",
       "...\n",
       "(34 other traces)\n",
       "...\n",
       "Z5.GB281..BHZ | 2014-08-24T10:20:44.294538Z - 2014-08-24T10:25:32.294538Z | 0.5 Hz, 145 samples\n",
       "\n",
       "[Use \"print(Stream.__str__(extended=True))\" to print all Traces]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# all the stations' data\n",
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response type: PolesZerosResponseStage, Stage Sequence Number: 1\n",
       "\tFrom M/S (VELOCITY in Meters per second) to V (VOLTAGE)\n",
       "\tStage gain: 3503.0, defined at 1.00 Hz\n",
       "\tTransfer function type: LAPLACE (RADIANS/SECOND)\n",
       "\tNormalization factor: 6029.25, Normalization frequency: 1.00 Hz\n",
       "\tPoles: (-0.0124773+0.0122177j), (-0.0124773-0.0122177j), (-34.0006+69.9823j), (-34.0006-69.9823j)\n",
       "\tZeros: 0j, 0j"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv = get_inventory()\n",
    "sta = inv.select(station='BKS')[0]\n",
    "net = sta[0].channels[0]\n",
    "net.response.get_paz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = obspy.read(\"./waveforms/*.mseed\")\n",
    "st[0].stats.delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-22ad471142ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_starttime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarttime\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmin_endtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendtime\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_endtime\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax_starttime\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m/\u001b[0m \u001b[0;36m0.04\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m st[0].interpolate(sampling_rate=25, method=\"lanczos\",\n\u001b[1;32m      5\u001b[0m                starttime=max_starttime, npts=npts, a=12)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'st' is not defined"
     ]
    }
   ],
   "source": [
    "max_starttime = max(tr.stats.starttime for tr in st)\n",
    "min_endtime = min(tr.stats.endtime for tr in st)\n",
    "npts = int((min_endtime - max_starttime)  / 0.04)\n",
    "st[0].interpolate(sampling_rate=25, method=\"lanczos\",\n",
    "               starttime=max_starttime, npts=npts, a=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "inv = obspy.Inventory(networks=[], source=\"\")\n",
    "\n",
    "# First read all station files.\n",
    "for filename in glob.glob(\"./stations/*.xml\"):\n",
    "    inv += obspy.read_inventory(filename)\n",
    "    \n",
    "# Now read the waveform files.\n",
    "st = obspy.read(\"./waveforms/*.mseed\")\n",
    "\n",
    "# Define Wood-Anderson Response\n",
    "paz_wa = {'sensitivity': 2800, 'zeros': [0j], 'gain': 1,\n",
    "          'poles': [-6.2832 - 4.7124j, -6.2832 + 4.7124j]} #https://docs.obspy.org/tutorial/advanced_exercise/advanced_exercise.html\n",
    "\n",
    "#st.remove_response(inventory=inv, water_level=60, output='DISP') # Remove instrument response\n",
    "\n",
    "# OR\n",
    "\n",
    "st.remove_response(inventory=inv, water_level=60) # Remove instrument response\n",
    "st.simulate(paz_simulate=paz_wa, water_level=60) # Simulate Wood-Anderson \n",
    "#st.integrate()  #Integrate to Convert Velocity to Displacemnt [what units?]\n",
    "\n",
    "#OR\n",
    "\n",
    "#tr.data = obspy.signal.invsim.estimate_wood_anderson_amplitude()\n",
    "\n",
    "st.detrend(\"linear\") # Linear Detrend\n",
    "st.taper(max_percentage=0.05) # Taper\n",
    "#st.filter(\"bandpass\", freqmin=0.001, freqmax=0.1, zerophase=True, corners=6) # Filter Response\n",
    "\n",
    "max_starttime = max(tr.stats.starttime for tr in st)\n",
    "min_endtime = min(tr.stats.endtime for tr in st)\n",
    "npts = int((min_endtime - max_starttime)  / 0.04)\n",
    "\n",
    "for tr in st:\n",
    "    tr.data = np.require(tr.data, requirements=[\"C_CONTIGUOUS\"]) \n",
    "    tr.data = tr.data*1000\n",
    "\n",
    "# Interpolate Data\n",
    "#st.interpolate(sampling_rate=0.5, method=\"lanczos\", starttime=max_starttime, npts=npts, a=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         network: BK\n",
       "         station: BKS\n",
       "        location: 00\n",
       "         channel: BHZ\n",
       "       starttime: 2014-08-24T10:20:14.069500Z\n",
       "         endtime: 2014-08-24T10:25:44.069500Z\n",
       "   sampling_rate: 40.0\n",
       "           delta: 0.025\n",
       "            npts: 13201\n",
       "           calib: 1.0\n",
       "         _format: MSEED\n",
       "           mseed: AttribDict({'byteorder': '>', 'dataquality': 'D', 'filesize': 45056, 'encoding': 'STEIM1', 'number_of_records': 11, 'record_length': 4096})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.select(station='BKS')[0].stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part D - Choose stations and compare amplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Pick three stations from the above plot.    \n",
    "\n",
    "       \n",
    "Try stations:     \n",
    "1) Roughly in a line and at different distances       \n",
    "2) Not in a line at the same distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the station labels here before running the cell below this one\n",
    "StationA = 'BKS'\n",
    "StationB = 'DBO'\n",
    "StationC = 'MOD'\n",
    "\n",
    "Stations = [StationA,StationB,StationC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "outer = gridspec.GridSpec(2, 2, wspace=0.2, hspace=0.2)\n",
    "\n",
    "for i in range(4):\n",
    "    inner = gridspec.GridSpecFromSubplotSpec(2, 1,\n",
    "                    subplot_spec=outer[i], wspace=0.1, hspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traces(Stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for showing the traces separately\n",
    "fig,axes = plt.subplots(3,1, sharex=True, sharey=True)\n",
    "Stations = [StationA,StationB,StationC]\n",
    "\n",
    "plot_separate_traces(Stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Amplitude, Distance and Magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amplitudes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate print the maximum amplitude at each station.     \n",
    "Just using the up-down (vertical) component of motion here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes = []\n",
    "\n",
    "for station in Stations:\n",
    "    amplitude = max(abs(st.select(station=station)[0].data))\n",
    "    amplitudes.append(amplitude)\n",
    "    \n",
    "print('Ampltiudes: \\n\\n \\\n",
    "        Station A - {} mm\\n \\\n",
    "        Station B - {} mm\\n \\\n",
    "        Station C - {} mm\\n'.format(amplitudes[0], amplitudes[1], amplitudes[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_lat_long(station):\n",
    "    stats = st.select(station=station)[0].stats\n",
    "    ID = '{}.{}.{}.{}'.format(stats.network, stats.station, stats.location, stats.channel)\n",
    "    lat = inv.get_coordinates(seed_id=ID)['latitude']\n",
    "    long = inv.get_coordinates(seed_id=ID)['longitude']\n",
    "    return lat, long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_epicentral_distance(event_lat, event_lon, sta_lat, sta_lon):\n",
    "    from obspy.geodetics import gps2dist_azimuth\n",
    "\n",
    "    epi_dist, az, baz = gps2dist_azimuth(event_lat, event_lon, sta_lat, sta_lon)\n",
    "    epi_dist = epi_dist / 1000 # Convert to km\n",
    "    \n",
    "    return epi_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_lat = cat[0].__dict__['origins'][0]['latitude']\n",
    "event_lon = cat[0].__dict__['origins'][0]['longitude']\n",
    "\n",
    "epi_dists = []\n",
    "\n",
    "for station in Stations:\n",
    "    lat, long = get_stat_lat_long(station)\n",
    "    epi_dist = calculate_epicentral_distance(event_lat, event_lon, lat, long)\n",
    "    epi_dists.append(epi_dist)\n",
    "\n",
    "print('Epicentral Distances: \\n\\n \\\n",
    "        Station A - {} km\\n \\\n",
    "        Station B - {} km\\n \\\n",
    "        Station C - {} km\\n'.format(epi_dists[0], epi_dists[1], epi_dists[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f033b6ad7103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# I encapsulated the above code into a function that shows distances and amplitudes of the stations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcalculate_distance_amplitude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-8e9fda68c655>\u001b[0m in \u001b[0;36mcalculate_distance_amplitude\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_distance_amplitude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mevent_lat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'origins'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mevent_lon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'origins'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cat' is not defined"
     ]
    }
   ],
   "source": [
    "# I encapsulated the above code into a function that shows distances and amplitudes of the stations\n",
    "calculate_distance_amplitude()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    {'Station': Stations,\n",
    "     'Distance [km]': epi_dists,\n",
    "     'Amplitude [mm]': amplitudes\n",
    "    })\n",
    "\n",
    "results[['Station', 'Distance [km]', 'Amplitude [mm]']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](fig1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the figure above, estimate the magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your guess of the magnitude here: [replace_me]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook developed by Alexander Robson, George Khalilieh\n",
    "\n",
    "Data Science Modules: http:/data.berkeley.edu/education/modules\n",
    "\n",
    "---\n",
    "***Please fill out our [feedback form](https://goo.gl/forms/s80KnMAWoozWoS2y1)! Thanks!***"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "142px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
